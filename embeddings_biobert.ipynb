{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14150d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67036e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f14a9a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/trishad2/PyTrial\n"
     ]
    }
   ],
   "source": [
    "%cd /home/trishad2/PyTrial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51c71141",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'lung/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085f7546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 13, 83]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(data_path+'full_datav3.csv',  index_col = 0)\n",
    "\n",
    "ae_cols = [i for i in data.columns if i.startswith('AE_')]\n",
    "med_cols = [i for i in data.columns if i.startswith('CM_')]\n",
    "treatment_cols = [i for i in data.columns if i.startswith('Treatment_')]\n",
    "feature_cols =    treatment_cols + med_cols + ae_cols\n",
    "vocab_size = [len(treatment_cols), len(med_cols), len(ae_cols)]\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1d27a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_id_dict={}\n",
    "for i in range(len(treatment_cols)):\n",
    "    treatment_id_dict[i]=treatment_cols[i].split('_')[1]\n",
    "    \n",
    "med_id_dict={}\n",
    "for i in range(len(med_cols)):\n",
    "    med_id_dict[i]=med_cols[i].split('_')[1]\n",
    "    \n",
    "ae_id_dict={}\n",
    "for i in range(len(ae_cols)):\n",
    "    ae_id_dict[i]=ae_cols[i].split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1dd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18d2e253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.1 were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Load the BioBERT model and tokenizer\n",
    "model = BertModel.from_pretrained('dmis-lab/biobert-base-cased-v1.1')\n",
    "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4720ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'APREPITANT',\n",
       " 1: 'DEXAMETHASONE',\n",
       " 2: 'FUROSEMIDE',\n",
       " 3: 'GRANISETRON',\n",
       " 4: 'MANNITOL',\n",
       " 5: 'METHYLPREDNISOLONE SODIUM SUCCINATE',\n",
       " 6: 'METOCLOPRAMIDE',\n",
       " 7: 'ONDANSETRON',\n",
       " 8: 'ONDANSETRON HYDROCHLORIDE',\n",
       " 9: 'PALONOSETRON',\n",
       " 10: 'PREDNISOLONE',\n",
       " 11: 'SODIUM CHLORIDE',\n",
       " 12: 'nan'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2c2fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary for embeddings\n",
    "medical_codes_embeddings = {}\n",
    "\n",
    "# Encode names and get word embeddings\n",
    "for code, name in med_id_dict.items():\n",
    "    tokens = tokenizer.tokenize(name)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    outputs = model(torch.tensor([input_ids]))\n",
    "    word_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    medical_codes_embeddings[code] = word_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a443e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_codes_embeddings={}\n",
    "# Encode names and get word embeddings\n",
    "for code, name in ae_id_dict.items():\n",
    "    tokens = tokenizer.tokenize(name)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    outputs = model(torch.tensor([input_ids]))\n",
    "    word_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    ae_codes_embeddings[code] = word_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4ed7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'med_emb_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(medical_codes_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c19c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'ae_emb_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(ae_codes_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e995d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89eb089e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'CISPLATIN', 1: 'COMBINED THERAPY', 2: 'GEMCITABINE'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f44322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_codes_embeddings={}\n",
    "# Encode names and get word embeddings\n",
    "for code, name in treatment_id_dict.items():\n",
    "    tokens = tokenizer.tokenize(name)\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    outputs = model(torch.tensor([input_ids]))\n",
    "    word_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    treatment_codes_embeddings[name] = word_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "180909ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'treatment_emb_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(treatment_codes_embeddings, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37309a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
